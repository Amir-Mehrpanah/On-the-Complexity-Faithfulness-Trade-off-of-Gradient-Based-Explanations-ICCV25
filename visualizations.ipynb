{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.stats import rankdata\n",
    "from itertools import product\n",
    "\n",
    "from src.datasets import get_cifar_test\n",
    "from src.paths import get_local_data_dir\n",
    "from src.utils import ActivationSwitch, LossSwitch, DatasetSwitch\n",
    "\n",
    "dataset = DatasetSwitch.CIFAR10\n",
    "\n",
    "bias = \"--nobias\"\n",
    "port = \"\"  # \"--port 5678\"\n",
    "block_main = \"\"  # \"--block_main\"\n",
    "batch_size = 64\n",
    "lr = 1e-4\n",
    "epochs = 50\n",
    "img_size = 32\n",
    "ckpt_mod = 10\n",
    "add_inverse = False\n",
    "losses = [\n",
    "    LossSwitch.CE,\n",
    "    # LossSwitch.MSE\n",
    "]\n",
    "activations = [\n",
    "    ActivationSwitch.RELU,\n",
    "    ActivationSwitch.LEAKY_RELU,\n",
    "    ActivationSwitch.SOFTPLUS_B1,\n",
    "    ActivationSwitch.SOFTPLUS_B10,\n",
    "    # ActivationSwitch.SOFTPLUS_B100,\n",
    "    # ActivationSwitch.SOFTPLUS_B1000,\n",
    "    # ActivationSwitch.SOFTPLUS_B10000,\n",
    "    # ActivationSwitch.SOFTPLUS_B100000,\n",
    "]\n",
    "\n",
    "COMPUTE_DATA_DIR = get_local_data_dir(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = get_cifar_test(\n",
    "    root_path=COMPUTE_DATA_DIR,\n",
    "    add_inverse=add_inverse,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(test_dataloader))\n",
    "x = x.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'checkpoints'\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_idx = 1\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "counter = 2\n",
    "for i, (activation, loss, epoch, bias) in enumerate(\n",
    "    product(\n",
    "        activations,\n",
    "        losses,\n",
    "        [epochs - 1],\n",
    "        [1],\n",
    "    )\n",
    "):\n",
    "    if bias == 1:\n",
    "        path = \"_False\"\n",
    "    elif bias == 0:\n",
    "        path = \"_True\"\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid bias value: {bias}\")\n",
    "\n",
    "    value = True if bias == 2 else False\n",
    "    conv_bias, fc_bias = (True, True) if bias == 0 else (False, value)\n",
    "\n",
    "    checkpoint_filename = f\"{activation}_{path}.pth\"\n",
    "\n",
    "    raw_image, label = training_data[image_idx]\n",
    "    image = raw_image.unsqueeze(0).to(device)\n",
    "    image.requires_grad = True\n",
    "\n",
    "    # Load the model from the checkpoint\n",
    "    activation_fn = convert_str_to_activation_fn(activation)\n",
    "    model = NeuralNetwork(activation_fn, conv_bias, True).to(device)\n",
    "    checkpoint_path = f\"{checkpoint_dir}/{checkpoint_filename}\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    output = model(image)\n",
    "    output.max().backward()\n",
    "    input_gradient = np.abs(image.grad.detach().cpu().numpy())\n",
    "    input_gradient = input_gradient / np.max(input_gradient)\n",
    "    plt.subplot(3, 3, counter)\n",
    "    counter += 2 if counter % 3 == 0 else 1\n",
    "    plt.imshow(input_gradient.squeeze())\n",
    "    plt.title(f\"Input Gradient {activation} {loss} {epoch} {bias}\")\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(raw_image.squeeze())\n",
    "plt.title(f\"input image {activation} {loss} {epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_idx = 0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "plt.figure(figsize=(20, 24))\n",
    "counter = 2\n",
    "for i,(activation,loss,epoch,bias,j,k) in enumerate(product(activations,[LossSwitch.CE],[epochs-1],[2],range(2),[0])):\n",
    "\n",
    "    if bias == 2:\n",
    "        path = \"_conv_False\"\n",
    "    elif bias == 1:\n",
    "        path = \"_False\"\n",
    "    elif bias == 0:\n",
    "        path = \"\"\n",
    "\n",
    "    value = True if bias == 2 else False\n",
    "    conv_bias,fc_bias = (True,True) if bias == 0 else (False,value)\n",
    "\n",
    "    checkpoint_filename = f'{activation}_{loss}_{epoch}{path}.pth'\n",
    "\n",
    "    raw_image, label = training_data[image_idx]\n",
    "    image = raw_image.unsqueeze(0).to(device)\n",
    "    image.requires_grad = True\n",
    "\n",
    "    # Load the model from the checkpoint\n",
    "    activation_fn = convert_str_to_activation_fn(activation)\n",
    "    model = NeuralNetwork(activation_fn,conv_bias,fc_bias).to(device)\n",
    "    checkpoint_path = f'{checkpoint_dir}/{checkpoint_filename}'\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    output = model(image)\n",
    "    output = output.max() if k == 0 else output.min()\n",
    "    output.backward()\n",
    "\n",
    "    input_gradient = image.grad.detach().cpu().numpy()\n",
    "    input_gradient = np.abs(input_gradient) if j == 0 else input_gradient\n",
    "    input_gradient = input_gradient/np.max(input_gradient)\n",
    "\n",
    "    plt.subplot(6, 5, counter)\n",
    "    counter += 2 if counter%5 == 0 else 1\n",
    "\n",
    "    minmax_str = 'max' if k == 0 else 'min'\n",
    "    abs_str = 'abs' if j == 0 else ''\n",
    "    cmap = 'Blues' if j == 0 else 'bwr'\n",
    "\n",
    "    plt.imshow(input_gradient.squeeze(),cmap=cmap)\n",
    "    plt.title(f'VG {activation} {abs_str} {minmax_str}')\n",
    "\n",
    "\n",
    "    expected_shape = input_gradient.squeeze().shape\n",
    "    U = rankdata(input_gradient.flatten()) / (input_gradient.squeeze().shape[0] * input_gradient.squeeze().shape[1])\n",
    "    U = U.reshape(expected_shape)\n",
    "    plt.subplot(6, 5, counter)\n",
    "    counter += 2 if counter%5 == 0 else 1\n",
    "    # U = np.stack([image.detach().cpu().numpy().squeeze(),U,np.zeros_like(U)],axis=2)\n",
    "    plt.imshow(U,cmap=cmap)\n",
    "\n",
    "    plt.title(f'IT {activation} {abs_str} {bias}')\n",
    "\n",
    "plt.subplot(1, 5, 1)\n",
    "plt.imshow(raw_image.squeeze())\n",
    "plt.title(f'input image {activation} {loss} {epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_idx = 1\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "\n",
    "for activation,epoch,bias in product(activations,[epochs-1],[2]):\n",
    "    if bias == 2:\n",
    "        path = \"_conv_False\"\n",
    "    elif bias == 1:\n",
    "        path = \"_False\"\n",
    "    elif bias == 0:\n",
    "        path = \"\"\n",
    "\n",
    "    value = True if bias == 2 else False\n",
    "    conv_bias,fc_bias = (True,True) if bias == 0 else (False,value)\n",
    "\n",
    "    checkpoint_filename = f'{activation}_{loss}_{epoch}{path}.pth'\n",
    "    raw_image, label = training_data[image_idx]\n",
    "    image = raw_image.unsqueeze(0).to(device)\n",
    "    image.requires_grad = True\n",
    "\n",
    "    activation_fn = convert_str_to_activation_fn(activation)\n",
    "    model = NeuralNetwork(activation_fn, conv_bias=conv_bias, fc_bias=fc_bias).to(device)\n",
    "    checkpoint_path = f'{checkpoint_dir}/{checkpoint_filename}'\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "\n",
    "    output = model(image)\n",
    "    output.max().backward()\n",
    "    input_gradient = np.abs(image.grad.detach().cpu().numpy())\n",
    "    input_gradient = input_gradient/np.max(input_gradient)\n",
    "\n",
    "    input_gradient = input_gradient.squeeze()\n",
    "    power_spectrum = compute_1d_power_spectrum(input_gradient)\n",
    "    # power_spectrum = power_spectrum[1:]\n",
    "    power_spectrum = power_spectrum/power_spectrum.sum()\n",
    "    plt.plot(power_spectrum[1:],alpha=0.8,label=checkpoint_filename) # remove constant component for better visualization\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Spectral Density')\n",
    "plt.title('Spectral Density of Input Gradient')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
